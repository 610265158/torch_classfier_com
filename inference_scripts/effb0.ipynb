{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config={\n",
    "    \"model_weights\":[\"../models//fold0_epoch_15_val_rocauc_0.992892_loss_0.053698.pth\",\n",
    "                    \"../models//fold1_epoch_17_val_rocauc_0.988631_loss_0.059439.pth\",\n",
    "                    \"../models//fold2_epoch_19_val_rocauc_0.991760_loss_0.052413.pth \",\n",
    "                    \"../models//fold3_epoch_19_val_rocauc_0.994017_loss_0.055336.pth\"],\n",
    "    \n",
    "    \n",
    "    \"model_structure\": \"tf_efficientnet_b0_ns\",\n",
    "    \"model_head_dim\": 1280,\n",
    "\n",
    "    \"sub_file\":\"../../sample_submission.csv\",\n",
    "    \"test_dir\":\"../../test\",\n",
    "    \"batch_size\":128*2,\n",
    "    \"num_thread\":4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import timm\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.model = timm.create_model('tf_efficientnet_b0_ns', pretrained=True)\n",
    "\n",
    "\n",
    "\n",
    "        self._avg_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "\n",
    "\n",
    "        self._fc = nn.Linear(1280 , num_classes, bias=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        #do preprocess\n",
    "\n",
    "\n",
    "        bs = X.size(0)\n",
    "        X=torch.cat([X,X,X],dim=1)\n",
    "        # Convolution layers\n",
    "        x = self.model.forward_features(X)\n",
    "        fm = self._avg_pooling(x)\n",
    "        fm = fm.view(bs, -1)\n",
    "\n",
    "\n",
    "        x = self._fc(fm)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model=Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_df():\n",
    "    test = pd.read_csv(model_config['sub_file'])\n",
    "\n",
    "    def get_test_file_path(image_id):\n",
    "            return model_config['test_dir'] + \"/{}/{}.npy\".format(\n",
    "                image_id[0], image_id\n",
    "            )\n",
    "    test['file_path'] = test['id'].apply(get_test_file_path)\n",
    "    return test\n",
    "\n",
    "test=get_test_df()\n",
    "\n",
    "\n",
    "\n",
    "class TestDataIter():\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.df = df\n",
    "        self.resize_trans=A.Resize(height=512, width=512)\n",
    "        \n",
    "\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        return self.single_map_func(self.df.iloc[item])\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "\n",
    "        return len(self.df)\n",
    "\n",
    "   \n",
    "    def single_map_func(self, dp):\n",
    "        \"\"\"Data augmentation function.\"\"\"\n",
    "        ####customed here\n",
    "        fname = dp['file_path']\n",
    "        \n",
    "\n",
    "        img = np.load(fname).astype(np.float32)[[0,2,4]]  # shape: (3, 273, 256)\n",
    "\n",
    "        ## to hwc\n",
    "        img = np.transpose(img,axes=[1,2,0])\n",
    "\n",
    "        \n",
    "\n",
    "        ## to chw\n",
    "        img = np.transpose(img, axes=[2,0,1])\n",
    "\n",
    "        img = np.vstack(img)  # shape: (819, 256)\n",
    "\n",
    "        transformed = self.resize_trans(image=img)\n",
    "        img = transformed['image']\n",
    "\n",
    "        img = np.expand_dims(img, 0)\n",
    "        \n",
    "        return img\n",
    "\n",
    "\n",
    "def get_dataiter():\n",
    "\n",
    "\n",
    "    test_generator = TestDataIter(test)\n",
    "    print(len(test_generator))\n",
    "    test_ds = DataLoader(test_generator,\n",
    "                             model_config['batch_size'],\n",
    "                             num_workers=model_config['num_thread'],\n",
    "                             shuffle=False)\n",
    "\n",
    "    return test_ds\n",
    "\n",
    "test_ds=get_dataiter()\n",
    "\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    \n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    text_preds = []\n",
    "\n",
    "    pres = []\n",
    "    weights=model_config[\"model_weights\"]\n",
    "    \n",
    "    for fold in range(len(weights)):\n",
    "        print(' infer with weight %s' % (weights[fold]))\n",
    "        model.load_state_dict(torch.load(weights[fold], map_location=device))\n",
    "\n",
    "        model.eval().to(device)\n",
    "        \n",
    "        one_fold_predictin=[]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images in tqdm(test_ds):\n",
    "                data = images.to(device).float()\n",
    "                \n",
    "                predictions = model(data)\n",
    "                predictions = torch.sigmoid(predictions).detach().cpu().numpy()\n",
    "                \n",
    "                one_fold_predictin.append(predictions)\n",
    "\n",
    "        one_fold_predictin=np.concatenate(one_fold_predictin).reshape(-1)\n",
    "        pres.append(one_fold_predictin)\n",
    "    \n",
    "    test['target']=np.mean(pres,0)\n",
    "    \n",
    "    test[['id','target']].to_csv('submission.csv',index=False)\n",
    "    \n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
